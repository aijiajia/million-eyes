{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2,), dtype=float32)\n[ 3.  5.]\n"
     ]
    }
   ],
   "source": [
    "# 3.1 计算图定义计算\n",
    "\n",
    "a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "result = a + b\n",
    "print(result)\n",
    "\n",
    "# 3.2 张量\n",
    "# 三个属性： name, shape,type\n",
    "# 3.3 会话（运行模型）执行计算\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17478476  0.1280534 ]\n"
     ]
    }
   ],
   "source": [
    "# 3.4.3 神经网络参数与TensorFlow变量\n",
    "# #声明w1 w2 两个变量。这里还通过seed参数设定了随机种子\n",
    "# #这样可以保证每次运行得到结果是一样的\n",
    "# w1 2行3列\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "# w2 3行1列\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "# [注意]w3 1行 2列\n",
    "w3 = tf.Variable(tf.truncated_normal([2], stddev=0.1))\n",
    "# b2 一行10列\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "# 暂时将输入定义一个常量。1*2 的矩阵\n",
    "\n",
    "x = tf.constant([[0.7,0.9]])\n",
    "\n",
    "# 计算神经网络的输出 a为1行3列\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "# page55\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    # print(sess.run(y))\n",
    "    # print(b2.eval())\n",
    "    # plt.plot(np.transpose(w3.eval()))\n",
    "    print(w3.eval())\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77436435]\n [-0.66980338]\n [-0.87685311]]\n"
     ]
    }
   ],
   "source": [
    "# placeholder \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1))\n",
    "\n",
    "# 定义placeholder作为存放输入数据的地方。这里维度也不一定要定义。\n",
    "# 如果维度是确定的，那么给出维度可以降低出错的概率。\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(3, 2), name = \"input\")\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y, feed_dict={x: [[0.7, 0.9],[0.1, 0.4],[0.5, 0.8]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps,cross entropy on all data is 0.0674925\n[[-0.81231821  1.4855988   0.06632921]\n [-2.44370413  0.1002484   0.59222424]]\n[[-0.81231821]\n [ 1.4855988 ]\n [ 0.06632937]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1000 training steps,cross entropy on all data is 0.0163385\n[[-1.27549374  1.93239319  0.71818316]\n [-2.82764411  0.47066161  1.14189851]]\n[[-1.21198606]\n [ 1.95956361]\n [ 0.55081969]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2000 training steps,cross entropy on all data is 0.00907547\n[[-1.51397622  2.1591146   1.07429051]\n [-3.01708913  0.64845419  1.46364999]]\n[[-1.40506411]\n [ 2.20634365]\n [ 0.83948904]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 3000 training steps,cross entropy on all data is 0.00714436\n[[-1.65394425  2.29218411  1.27439237]\n [-3.14156055  0.76467752  1.66820383]]\n[[-1.52613485]\n [ 2.35394239]\n [ 1.01985705]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 4000 training steps,cross entropy on all data is 0.00578471\n[[-1.79143536  2.42184758  1.46388769]\n [-3.28938985  0.90241849  1.88527477]]\n[[-1.66073918]\n [ 2.50406837]\n [ 1.20711744]]\n"
     ]
    }
   ],
   "source": [
    "# 完整神经网络样例程序，解决二分类\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Numpy是科学计算工具包，通过Numpy工具包生成模拟数据\n",
    "from numpy.random import RandomState\n",
    "\n",
    "# 定义训练数据的batch大小\n",
    "batch_size = 8\n",
    "\n",
    "# 定义神经网络的参数\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "# 在shape 的一个维度上使用Ｎone可以方便使用不同batch大小。在训练时需要把数据\n",
    "# 分成比较小的batch，但是测试时，可以一次使用全部数据。当数据集比较小时这样比较\n",
    "# 方便测试，但是数据集比较大时，将大量数据放入一个batch可能会导致内存溢出。\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None, 2], name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32,shape=[None, 1], name=\"y-input\")\n",
    "\n",
    "# 定义神经网络的传播过程\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "# 定义损失函数和反向传播算法\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(\n",
    "    y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))\n",
    ")\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# 通过随机数生成一个模拟数据集 128*2\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "\n",
    "# 定义规则来给出样本的标签。这里所有x1+x2 < 1 的样例都被认为是正样本（比如零件合格），\n",
    "# 而其他为负样本（比如零件不合格）。和TensorFlow游乐场中的表示法不大一样的是，在这里使用\n",
    "# 0 表示负样本，1 来表示正样本。大部分分类问题的神经网络都会采用 0 和 1 的表示方法。\n",
    "# int(True) -> 1\n",
    "\n",
    "\n",
    "# 放在列表中的生成的是每一次生成一个列表\n",
    "# from numpy.random import RandomState\n",
    "# rdm = RandomState(1)\n",
    "# dataset_size = 4\n",
    "# X = rdm.rand(dataset_size, 2)\n",
    "# Y1 = [[int(x1+x2 < 1)] for (x1,x2) in X ]\n",
    "# Y2 = [int(x1+x2 < 1) for (x1,x2) in X ]\n",
    "# # print(type(Y1),\" == \",type(Y2))\n",
    "# print(Y1)\n",
    "# [[0], [1], [1], [1]]\n",
    "# print(Y2)\n",
    "# [0, 1, 1, 1]\n",
    "\n",
    "# 根据X生成的标签\n",
    "Y = [[int(x1+x2 < 1)] for (x1,x2) in X ]\n",
    "\n",
    "# 创建会话运行TensorFlow程序\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    # 初始化变量\n",
    "    sess.run(init_op)\n",
    "    # print(sess.run(w1))\n",
    "    # print(sess.run(w2))  \n",
    "    # 训练指定的轮数\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        # 每次选取batch_size个样本进行训练。 重复使用\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        \n",
    "        # 通过选取的样本训练神经网络并更新参数\n",
    "        sess.run(\n",
    "            train_step, feed_dict={x: X[start:end], y_: Y[start:end]}\n",
    "        )\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(\n",
    "                cross_entropy, feed_dict={x: X, y_: Y}\n",
    "            )\n",
    "            print(\"After %d training steps,cross entropy on all data is %g\" %(i, total_cross_entropy))\n",
    "            print(sess.run(w1)) \n",
    "            print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}